# üèóÔ∏è AI Building Classifier

This project is a from-scratch convolutional neural network built using PyTorch to classify architectural images. The model begins with simple binary classification (e.g., **residential** vs **industrial**) and is evolving toward a full **multi-class architecture recognition system**, including both **cultural origins** (e.g., Egyptian, Chinese, Greek) and **stylistic classifications** (e.g., Renaissance, Baroque).

What makes this project different is that it mirrors **how humans learn** ‚Äî through *meaningful memory*. The model saves the most significant examples from each training run (best and worst) and reuses them during future training to simulate a kind of **learning memory**. This concept is known in machine learning as *replay buffering* or *exemplar memory*, but it was developed here from a natural human insight.

---

## üöÄ Features Implemented

- [x] CNN model built from scratch in PyTorch
- [x] DuckDuckGo image scraping with multi-query support
- [x] Training and validation dataset pipeline
- [x] Memory replay buffer (save most & least accurate samples)
- [x] Resume training with memory-injected batches
- [x] Binary classifier (residential vs industrial)
- [x] Multi-class cultural classifier (Chinese, Egyptian, European, Greek, Indian)

---

## üß† Conceptual Design

Rather than just train on more and more data, this model is designed to **remember what mattered**. Each epoch, it saves the 10 most confidently correct and 10 most confusing samples. These are injected into future training runs, ensuring that the model is learning **not just more, but better**.

This concept is based on how humans often return to defining moments in our learning journeys ‚Äî both successes and failures ‚Äî to anchor deeper understanding.

---

## üõ£Ô∏è Roadmap

### ‚úÖ Phase 1 ‚Äî Binary Classification
- Residential vs Industrial buildings using scraped data

### ‚úÖ Phase 2 ‚Äî Multi-Class Cultural Classification
- Categories like: Egyptian, Chinese, Greek, Indian, European
- Replay buffer extended to multi-class scenario
- Achieved ~79% accuracy on validation

### üîú Phase 3 ‚Äî Fine-Grained Architectural Style Classification
- Classify architectural **styles** within cultural categories
- Examples: Renaissance, Baroque, Gothic, Brutalist, Neoclassical

### üîÆ Phase 4 ‚Äî Self-Improving Memory Loop
- Use replay memory to auto-refine misclassifications
- Incorporate knowledge-based reasoning and image similarity
- Move closer to human-like adaptive learning

---

## üìÇ Project Structure

```
AI_Building_Classifier/
‚îú‚îÄ‚îÄ Data/               
‚îÇ   ‚îú‚îÄ‚îÄ Raw/                   # Raw scraped images
‚îÇ   ‚îú‚îÄ‚îÄ Training/              # Structured train/val folders
‚îÇ   ‚îú‚îÄ‚îÄ Val/                   # Structured train/val folders
‚îú‚îÄ‚îÄ models/                    # Saved model checkpoints
‚îú‚îÄ‚îÄ replay_buffer/             # Stored key images from past runs
‚îú‚îÄ‚îÄ model.py                   # CNN architecture
‚îú‚îÄ‚îÄ train.py                   # Basic training loop
‚îú‚îÄ‚îÄ replay_train.py            # Training with replay buffer
‚îú‚îÄ‚îÄ replay_multiclass_train.py # Multi-class training with memory
‚îú‚îÄ‚îÄ evaluate.py                # Model evaluation script
‚îú‚îÄ‚îÄ download_image_cultures.py # Image scraper for cultural classes
‚îú‚îÄ‚îÄ dataset_splitter.py        # Train/val image sorter
‚îî‚îÄ‚îÄ JOURNAL.md                 # Thought log and original ideas
```

---

## üìâ Training Loss Over Time
![multi_training_loss](https://github.com/user-attachments/assets/04152e25-d360-4d03-bbda-b7eb0dd29d8a)

---

## üìä Multi-Class Validation Results (Phase 2)

| Class     | Precision | Recall | F1-score |
|-----------|-----------|--------|----------|
| Chinese   | 0.94      | 0.78   | 0.85     |
| Egyptian  | 0.74      | 0.86   | 0.80     |
| European  | 0.70      | 0.77   | 0.73     |
| Greek     | 0.91      | 0.83   | 0.87     |
| Indian    | 0.70      | 0.69   | 0.70     |
| **Avg**   | **0.80**  | **0.79** | **0.79** |

---

## ‚ôªÔ∏è Phase 4 ‚Äî Replay-Based Self-Improvement

The model now incorporates a **replay refinement loop**, where it:
- Logs predictions on the validation set during training.
- Extracts high-confidence correct (`focus`) and high-confidence incorrect (`reinforce`) samples.
- Re-injects these samples during future training to focus on meaningful mistakes and strengths.

This mimics how humans review both best and worst examples to deepen understanding.

### üß† Replay Training Curve

| Epoch | Train Acc | Val Acc | Replay Loss |
|-------|-----------|---------|-------------|
| 1     | 39.02%    | 43.40%  | 1.43        |
| 2     | 50.73%    | 53.77%  | 1.15        |
| 3     | 56.10%    | 64.15%  | 1.30        |
| 4     | 58.78%    | 66.98%  | 1.34        |
| 5     | 58.05%    | 66.04%  | 0.95        |
| 6     | 62.68%    | 55.66%  | 1.24        |
| 7     | 58.54%    | 63.21%  | 1.39        |
| 8     | 62.20%    | 60.38%  | 1.01        |
| 9     | 66.59%    | 63.21%  | 1.38        |
| 10    | 66.34%    | 71.70%  | 1.21        |

### üìà Replay + Focus Training Plot

![Replay Focus Training Loss](plots/replay_focus_training.png)

> üìù Logs and plots are stored under `/checkpoints/` and `/plots/`. Replay samples in `/replay/`. See `Journal.md` for full self-training idea flow.

---

## üßæ License & Attribution

## License

This project is currently released under a **source-available, non-commercial license**.

You are free to:
- View, learn from, and experiment with the code for **personal or educational use**.

You may **not**:
- Use this project or its derivatives for **commercial purposes** (including SaaS, resale, client work, or monetized tools).

A future license may allow commercial usage under specific conditions.

See [LICENSE.md](./LICENSE.md) for full details.

Some code co-developed with the help of ChatGPT-5.1.
